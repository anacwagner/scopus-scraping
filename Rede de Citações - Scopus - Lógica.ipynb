{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REDE DE CITAÇÕES - SCOPUS - LÓGICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\Documents\\WOS_CitationNetworks\n"
     ]
    }
   ],
   "source": [
    "# CARREGANDO BIBLIOTECAS\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "import OpenSSL.SSL\n",
    "import getpass\n",
    "\n",
    "import pybliometrics\n",
    "import pybliometrics.scopus as sc\n",
    "\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from math import *\n",
    "\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "import gc \n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import configparser as cf\n",
    "\n",
    "path_atual = os.getcwd()\n",
    "print(path_atual)\n",
    "path_download = '../../Downloads/'\n",
    "path_scopus = '../../../Walter/.scopus'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O **pybliometrics** (anteriormente **scopus**) usa um arquivo de configuração `~/.scopus/config.ini` para salvar credenciais e nomes de diretório da pasta que armazena arquivos em cache.\n",
    "\n",
    "Para alterar sua chave ou alterar diretórios para arquivos em cache, edite esse arquivo manualmente e importe pybliometrics novamente.\n",
    "\n",
    "Se o arquivo de configuração não existir, o pybliometrics emitirá um aviso. Para gerar o arquivo de configuração, faça o seguinte comando `pybliometrics.utils.create_config()` logo após a importação.\n",
    "\n",
    "\n",
    "A **pybliometrics** solicita suas credenciais. A maioria dos usuários só precisa fornecer a chave da API e pressionar Enter no segundo prompt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CONFIGURAÇÕES\n",
    "#pybliometrics.utilis.create_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CATEGORIA PESQUISADA\n",
    "category = 'LOGIC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. No WoS, escolher uma área de pubicação e obter a listagem de periódicos.\n",
    "\n",
    "Usando o Web of Science, obter uma listagem de todos os periódicos publicados na categoria escolhida (**MATHEMATICS**). A fim de filtrar os resultados, foi escolhida uma subárea: **LOGIC**.\n",
    "\n",
    "* Em `Advanced Search` do WoS, pesquisar: `WC=(MATHEMATICS)` e selecionar a opção de apenas artigos. São encontrados 1.268.522 artigos. \n",
    "\n",
    "\n",
    "* Em seguida, selecionar o filtro de categoria do WoS, `LOGIC`. Agora, são eoncontrados 13.030 artigos. \n",
    "\n",
    "\n",
    "\n",
    "* No campo de filtros, tem a opção `Source Titles`. Ir em `more options / values...`. Com a página atualizada, ir em ` Analyze results`.\n",
    "\n",
    "\n",
    "* Novamente, escolher a opção `Source Titles`. \n",
    "\n",
    "\n",
    "* No final da página, selecionar a opção `All data rows (up to 100,000)` e realizar o download. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figuras/journalsVis_LOGIC.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_journals = pd.read_csv('journals/SourceTitles_' + category + '.txt', sep='\\t',index_col=False)\n",
    "file_journals.index += 1 \n",
    "file_journals = file_journals[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source Titles</th>\n",
       "      <th>records</th>\n",
       "      <th>% of 13030</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JOURNAL OF SYMBOLIC LOGIC</td>\n",
       "      <td>3944.0</td>\n",
       "      <td>30.269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANNALS OF PURE AND APPLIED LOGIC</td>\n",
       "      <td>2232.0</td>\n",
       "      <td>17.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MATHEMATICAL LOGIC QUARTERLY</td>\n",
       "      <td>1322.0</td>\n",
       "      <td>10.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARCHIVE FOR MATHEMATICAL LOGIC</td>\n",
       "      <td>1126.0</td>\n",
       "      <td>8.642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JOURNAL OF ALGORITHMS</td>\n",
       "      <td>852.0</td>\n",
       "      <td>6.539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LOGIC JOURNAL OF THE IGPL</td>\n",
       "      <td>749.0</td>\n",
       "      <td>5.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>STUDIA LOGICA</td>\n",
       "      <td>489.0</td>\n",
       "      <td>3.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ALGEBRA AND LOGIC</td>\n",
       "      <td>479.0</td>\n",
       "      <td>3.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>REVIEW OF SYMBOLIC LOGIC</td>\n",
       "      <td>359.0</td>\n",
       "      <td>2.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BULLETIN OF SYMBOLIC LOGIC</td>\n",
       "      <td>350.0</td>\n",
       "      <td>2.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>JOURNAL OF ALGORITHMS COGNITION INFORMATICS AN...</td>\n",
       "      <td>319.0</td>\n",
       "      <td>2.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NOTRE DAME JOURNAL OF FORMAL LOGIC</td>\n",
       "      <td>319.0</td>\n",
       "      <td>2.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>JOURNAL OF APPLIED LOGIC</td>\n",
       "      <td>287.0</td>\n",
       "      <td>2.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>JOURNAL OF MATHEMATICAL LOGIC</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>REPORTS ON MATHEMATICAL LOGIC</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LECTURE NOTES IN MATHEMATICS</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>STOCHASTIC CALCULUS WITH INFINITESIMALS</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CONSTRUCTIVE COMMUTATIVE ALGEBRA PROJECTIVE MO...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MODEL THEORY IN ALGEBRA ANALYSIS AND ARITHMETIC</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Source Titles  records  % of 13030\n",
       "1                           JOURNAL OF SYMBOLIC LOGIC   3944.0      30.269\n",
       "2                    ANNALS OF PURE AND APPLIED LOGIC   2232.0      17.130\n",
       "3                        MATHEMATICAL LOGIC QUARTERLY   1322.0      10.146\n",
       "4                      ARCHIVE FOR MATHEMATICAL LOGIC   1126.0       8.642\n",
       "5                               JOURNAL OF ALGORITHMS    852.0       6.539\n",
       "6                           LOGIC JOURNAL OF THE IGPL    749.0       5.748\n",
       "7                                       STUDIA LOGICA    489.0       3.753\n",
       "8                                   ALGEBRA AND LOGIC    479.0       3.676\n",
       "9                            REVIEW OF SYMBOLIC LOGIC    359.0       2.755\n",
       "10                         BULLETIN OF SYMBOLIC LOGIC    350.0       2.686\n",
       "11  JOURNAL OF ALGORITHMS COGNITION INFORMATICS AN...    319.0       2.448\n",
       "12                 NOTRE DAME JOURNAL OF FORMAL LOGIC    319.0       2.448\n",
       "13                           JOURNAL OF APPLIED LOGIC    287.0       2.203\n",
       "14                      JOURNAL OF MATHEMATICAL LOGIC    117.0       0.898\n",
       "15                      REPORTS ON MATHEMATICAL LOGIC     65.0       0.499\n",
       "16                       LECTURE NOTES IN MATHEMATICS     21.0       0.161\n",
       "17            STOCHASTIC CALCULUS WITH INFINITESIMALS     11.0       0.084\n",
       "18  CONSTRUCTIVE COMMUTATIVE ALGEBRA PROJECTIVE MO...      5.0       0.038\n",
       "19    MODEL THEORY IN ALGEBRA ANALYSIS AND ARITHMETIC      5.0       0.038"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SourceTitles = list(file_journals['Source Titles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_years = pd.read_csv('journals/PublicationYears_' + category + '.txt', sep='\\t',index_col=False)\n",
    "file_years.index += 1 \n",
    "file_years = file_years[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Publication Years</th>\n",
       "      <th>records</th>\n",
       "      <th>% of 13030</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>141.0</td>\n",
       "      <td>1.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>453.0</td>\n",
       "      <td>3.477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>531.0</td>\n",
       "      <td>4.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>523.0</td>\n",
       "      <td>4.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015</td>\n",
       "      <td>509.0</td>\n",
       "      <td>3.906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Publication Years  records  % of 13030\n",
       "1              2019    141.0       1.082\n",
       "2              2018    453.0       3.477\n",
       "3              2017    531.0       4.075\n",
       "4              2016    523.0       4.014\n",
       "5              2015    509.0       3.906"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_years.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Publication Years</th>\n",
       "      <th>records</th>\n",
       "      <th>% of 13030</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1970</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1969</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1968</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1967</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1966</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Publication Years  records  % of 13030\n",
       "50              1970     39.0       0.299\n",
       "51              1969     53.0       0.407\n",
       "52              1968     45.0       0.345\n",
       "53              1967     37.0       0.284\n",
       "54              1966     42.0       0.322"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_years.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PublicationYears = list(file_years['Publication Years'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Usando a API do Scopus, pesquisar os artigos publicados por cada periódico.\n",
    "\n",
    "Usando a função [**ScopusSearch**](https://scopus.readthedocs.io/en/stable/examples/ScopusSearch.html), buscamos pelo nome de cada periódico (`SourceTitles`) em um intervalo de tempo pré-definido de 1960 a 2018. \n",
    "\n",
    "* O nome do periódico deve ser colocado entre aspas duplas para ser pesquisado como uma string, caso contrário será pesquisado como uma interseção das palavras que estão contidas no nome. \n",
    "\n",
    "` documents = sc.ScopusSearch('SRCTITLE (\"' + str(journal) + '\")  AND  PUBDATETXT (' + str(year) + ') AND DOCTYPE(ar) AND SRCTYPE (j)', refresh=True, apiKey=keys[k])`\n",
    "\n",
    "`documents = sc.ScopusSearch('SRCTITLE ( \"JOURNAL OF SYMBOLIC LOGIC\" )  AND  PUBDATETXT (2018) AND DOCTYPE(ar) AND SRCTYPE (j)', refresh=True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemo gerar apenas 10 chaves de uma só vez, todas foram armazenadas em uma lista para ser usada durante o processo de extração. Caso o valor seja excedido, a extração irá parar e novas chaves derão ser geradas [manualmente](https://dev.elsevier.com/apikey/manage) e substituídas na lista `keys`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createKeys(password,email,op=1):\n",
    "    # op=1: gera as 10 primeiras chaves (ainda não tenm nenhuma chave gerada)\n",
    "    # op=2: gera 10 novas chaves (deleta as 10 já existentes e depois faz a geração das chaves)\n",
    "    \n",
    "    driver = webdriver.Chrome(executable_path = r'/Users/Walter/Documents/chromedriver')\n",
    "\n",
    "    scopus_api_link = 'https://dev.elsevier.com/apikey/manage'\n",
    "    driver.get(scopus_api_link)\n",
    "\n",
    "    driver.find_element_by_xpath('//*[@id=\"bdd-email\"]').send_keys(email)\n",
    "    driver.find_element_by_xpath('//*[@id=\"bdd-elsPrimaryBtn\"]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"bdd-password\"]').send_keys(password)\n",
    "    driver.find_element_by_xpath('//*[@id=\"bdd-elsPrimaryBtn\"]').click()\n",
    "    \n",
    "    if op==2:\n",
    "        # deletar todas as dez chaves existentes\n",
    "        for key in range(1,11):\n",
    "            time.sleep(5)\n",
    "            driver.find_element_by_xpath('/html/body/div[1]/div[4]/div[2]/div[1]/table/tbody/tr[1]/td[4]/a').click()\n",
    "            driver.find_element_by_xpath('//*[@id=\"delregister\"]').click()\n",
    "            time.sleep(5)\n",
    "            driver.find_element_by_xpath('//*[@id=\"deleteModal\"]/div/div/div[3]/button[1]').click()\n",
    "    \n",
    "    if op==1 or op==2:\n",
    "        # criar todas as dez chaves permitidas\n",
    "        for key in range(1,11):\n",
    "            time.sleep(5)\n",
    "            driver.find_element_by_xpath('/html/body/div[1]/div[4]/div[2]/h2/span/a').click()\n",
    "            driver.find_element_by_xpath('//*[@id=\"projectName\"]').send_keys('scopus'+str(key))\n",
    "            driver.find_element_by_xpath('//*[@id=\"websiteURL\"]').send_keys('https://github.com/anacwagner/')\n",
    "            driver.find_element_by_xpath('//*[@id=\"apicheckbox\"]/div/label').click()  \n",
    "            driver.find_element_by_xpath('//*[@id=\"tdmcheckbox\"]/div/label').click()\n",
    "            driver.find_element_by_xpath('//*[@id=\"register\"]').click()   \n",
    "        \n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source,'lxml')\n",
    "    findAll = soup.findAll('a')\n",
    "    \n",
    "    keys = []\n",
    "    for i in range(10,20):\n",
    "        keys.append(findAll[i].text)\n",
    "        \n",
    "    driver.quit()\n",
    "    \n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Password:········\n"
     ]
    }
   ],
   "source": [
    "password = getpass.getpass('Password:')\n",
    "email = 'acwgdb@gmail.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f5864a403461fc0434e84b1d7c1d2e48',\n",
       " '838bf38054e9f78bbf383890a5b637af',\n",
       " '093c245e896498ae73920aedf1270ed5',\n",
       " '14bb24aaae728c626a0e11adf2c0e34d',\n",
       " 'a8f55b07e4df954138c8055c55541837',\n",
       " '69845d3dfc7a3b9be3af6343be4728f9',\n",
       " 'fde8c4f78a58cb7b698c3b8fa73fe77a',\n",
       " '0a3d9afb6dd5a69cee2b593778dff84f',\n",
       " 'faba95e0f0006c634229394a4aa05fe6',\n",
       " '3e3fe942f06880df31d76f64eb9eac4f']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = createKeys(password,email)\n",
    "keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sempre que gerarmos novas chaves, devemos modificá-la no arquivo de configurações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def changeKeys(k,keys):\n",
    "    config = cf.ConfigParser()\n",
    "    config.read(path_scopus + '/config.ini')\n",
    "    config.set(\"Authentication\", \"apikey\", keys[k])\n",
    "    with open(path_scopus + '/config.ini', \"w+\") as configfile:\n",
    "        config.write(configfile)\n",
    "    print('Nova Chave: ' + config.get(\"Authentication\", \"apikey\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "changeKeys(0,keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segue um exemplo da pesquisa que vamos realizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de resultados encontrados: 87 artigos.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eid</th>\n",
       "      <th>doi</th>\n",
       "      <th>pii</th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>title</th>\n",
       "      <th>subtype</th>\n",
       "      <th>creator</th>\n",
       "      <th>afid</th>\n",
       "      <th>affilname</th>\n",
       "      <th>affiliation_city</th>\n",
       "      <th>...</th>\n",
       "      <th>issueIdentifier</th>\n",
       "      <th>article_number</th>\n",
       "      <th>pageRange</th>\n",
       "      <th>description</th>\n",
       "      <th>authkeywords</th>\n",
       "      <th>citedby_count</th>\n",
       "      <th>openaccess</th>\n",
       "      <th>fund_acr</th>\n",
       "      <th>fund_no</th>\n",
       "      <th>fund_sponsor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2-s2.0-85061941438</td>\n",
       "      <td>10.1017/jsl.2017.89</td>\n",
       "      <td>S0022481217000895</td>\n",
       "      <td>None</td>\n",
       "      <td>Profiniteness in finitely generated varieties ...</td>\n",
       "      <td>ar</td>\n",
       "      <td>Nurakunov A.</td>\n",
       "      <td>60072558;60003675</td>\n",
       "      <td>Kyrgyz National Academy of Sciences;Politechni...</td>\n",
       "      <td>Bishkek;Warsaw</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>1566-1578</td>\n",
       "      <td>© The Association for Symbolic Logic 2018. Pro...</td>\n",
       "      <td>profinite algebras | standard varieties | unde...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>undefined</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2-s2.0-85061938998</td>\n",
       "      <td>10.1017/jsl.2018.35</td>\n",
       "      <td>S002248121800035X</td>\n",
       "      <td>None</td>\n",
       "      <td>Berkeley cardinals and the structure of l(v&amp;am...</td>\n",
       "      <td>ar</td>\n",
       "      <td>Cutolo R.</td>\n",
       "      <td>60017293</td>\n",
       "      <td>Università degli Studi di Napoli Federico II</td>\n",
       "      <td>Naples</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>1457-1476</td>\n",
       "      <td>© The Association for Symbolic Logic 2018.  We...</td>\n",
       "      <td>Berkeley cardinals | choiceless large cardinal...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>undefined</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  eid                  doi                pii pubmed_id  \\\n",
       "1  2-s2.0-85061941438  10.1017/jsl.2017.89  S0022481217000895      None   \n",
       "2  2-s2.0-85061938998  10.1017/jsl.2018.35  S002248121800035X      None   \n",
       "\n",
       "                                               title subtype       creator  \\\n",
       "1  Profiniteness in finitely generated varieties ...      ar  Nurakunov A.   \n",
       "2  Berkeley cardinals and the structure of l(v&am...      ar     Cutolo R.   \n",
       "\n",
       "                afid                                          affilname  \\\n",
       "1  60072558;60003675  Kyrgyz National Academy of Sciences;Politechni...   \n",
       "2           60017293       Università degli Studi di Napoli Federico II   \n",
       "\n",
       "  affiliation_city     ...      issueIdentifier article_number  pageRange  \\\n",
       "1   Bishkek;Warsaw     ...                    4           None  1566-1578   \n",
       "2           Naples     ...                    4           None  1457-1476   \n",
       "\n",
       "                                         description  \\\n",
       "1  © The Association for Symbolic Logic 2018. Pro...   \n",
       "2  © The Association for Symbolic Logic 2018.  We...   \n",
       "\n",
       "                                        authkeywords citedby_count openaccess  \\\n",
       "1  profinite algebras | standard varieties | unde...             1          0   \n",
       "2  Berkeley cardinals | choiceless large cardinal...             0          0   \n",
       "\n",
       "  fund_acr    fund_no fund_sponsor  \n",
       "1     None  undefined         None  \n",
       "2     None  undefined         None  \n",
       "\n",
       "[2 rows x 33 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = sc.ScopusSearch('SRCTITLE (\"' + str(SourceTitles[0]) + '\")  AND  PUBDATETXT (' + str(2018) + ') AND DOCTYPE(ar) AND SRCTYPE ( j )', refresh=True)\n",
    "print('Total de resultados encontrados: ' + str(documents.get_results_size()) + ' artigos.')\n",
    "df_documents = pd.DataFrame(pd.DataFrame(documents.results))\n",
    "df_documents.index += 1 \n",
    "df_documents.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "O resultado da pesquisa sobre `documents` nos permite ter acesso às seguintes informações:\n",
    "\n",
    "Index(['eid', 'doi', 'pii', 'pubmed_id', 'title', 'subtype', 'creator', 'afid',\n",
    "       'affilname', 'affiliation_city', 'affiliation_country', 'author_count',\n",
    "       'author_names', 'author_ids', 'author_afids', 'coverDate',\n",
    "       'coverDisplayDate', 'publicationName', 'issn', 'source_id', 'eIssn',\n",
    "       'aggregationType', 'volume', 'issueIdentifier', 'article_number',\n",
    "       'pageRange', 'description', 'authkeywords', 'citedby_count',\n",
    "       'openaccess', 'fund_acr', 'fund_no', 'fund_sponsor'],\n",
    "      dtype='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mensagens de Erro\n",
    "Uma exceção é gerada quando o status do download não está ok. Isso evita que informações com falha (ou seja, o status e a mensagem do erro) sejam salvas como arquivo em cache. Essas exceções são da classe base ScopusException.\n",
    "\n",
    "Algumas delas, são:\n",
    "\n",
    " \n",
    "* `pybliometrics.scopus.exception.Scopus404Error`: **NOT FOUND**\n",
    "A entidade que você está procurando não existe. Verifique se o seu identificador ainda está apontando para o item que você está procurando.\n",
    "\n",
    "\n",
    "* `pybliometrics.scopus.exception.Scopus429Error`: **QUOTA EXCEEDED**\n",
    "O limite semanal de 5000 solicitações da chave de API fornecida (para visualizações padrão) está esgotado. Aguarde uma semana ou altere a chave em `~/.scopus /config.ini.`.\n",
    "\n",
    "\n",
    "* `pybliometrics.scopus.exception.Scopus500Error`: **INTERNAL SERVER ERROR**\n",
    "Formalmente, o servidor não responde, por vários motivos. Um motivo comum nas pesquisas é que você usa um nome de campo que não existe. Verifique se sua consulta funciona na Pesquisa avançada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def allArticlesSource(journalsSourceTitles, PublicationYears):\n",
    "    \n",
    "    source_eids = []\n",
    "    \n",
    "    i = len(source_eids) + 1\n",
    "    k = 0 # controle da chave da API\n",
    "    \n",
    "    for journal in journalsSourceTitles[i-1:]:\n",
    "        print('\\n ' + str(i) + '. Início da extração dos artigos do periódico \\n' + journal)\n",
    "        \n",
    "        eids = []\n",
    "        \n",
    "        for year in range(int(PublicationYears[-1]),2019):\n",
    "            \n",
    "            resultado = False\n",
    "            \n",
    "            while resultado == False:\n",
    "                try: \n",
    "                    documents = sc.ScopusSearch('SRCTITLE (\"' + str(journal) + '\")  AND  PUBDATETXT (' + str(year) + ') AND DOCTYPE(ar) AND  SRCTYPE (j)')\n",
    "                    eids.append(documents.get_eids())\n",
    "                    resultado = True\n",
    "                    \n",
    "                except sc.exception.Scopus404Error:  #NOT FOUND\n",
    "                    resultado = True\n",
    "                except sc.exception.Scopus429Error : #QUOTA EXCEEDED\n",
    "                    k = k + 1\n",
    "                    if k == 11:\n",
    "                        keys = createKeys(password,email)\n",
    "                        k = 0\n",
    "                        changeKeys(k,keys)\n",
    "                    else:\n",
    "                        changeKeys(k,keys)\n",
    "                except sc.exception.Scopus500Error:  #INTERNAL SERVER ERROR\n",
    "                    time.sleep(14)\n",
    "\n",
    "        source_eids.append(eids)\n",
    "        i = i + 1\n",
    "\n",
    "        with open('pickles/' + category + '_eids.pickle', 'wb') as f:\n",
    "            pickle.dump([source_eids], f)\n",
    "        \n",
    "        #os.remove(path_scopus + '/scopus_search/COMPLETE/' + eid)\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allArticlesSource(SourceTitles, PublicationYears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('pickles/' + category + '_eids.pickle', 'rb') as f:\n",
    "    source_eids = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variável `source_eids` é uma lista de listas que armazena os códigos de identificação dos artigos publicados por cada periódico em cada ano. Cada ano é uma lista dentro da lista das publicações do periódico correpondente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de artigos da base: 18718\n"
     ]
    }
   ],
   "source": [
    "articlesSource = list(itertools.chain.from_iterable(source_eids))\n",
    "articlesSource = list(itertools.chain.from_iterable(articlesSource))\n",
    "articlesSource = list(set(list(itertools.chain.from_iterable(articlesSource))))\n",
    "print('Total de artigos da base: ' + str(len(articlesSource)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Usando a API do Scopus, extrair e armazenar as informações de cada artigo.\n",
    "\n",
    "As informações extraídas são armazenadas em dois diconários, um contendo as informações dos artigos (**info_articles**) e outro contendo as informações dos periódicos (**info_journals**). Essas estruturas foram pensadas para serem utilizadas no **PyMongo**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keyNumber():\n",
    "    # Qual a chave que está sendo utilizada\n",
    "    config = cf.ConfigParser()\n",
    "    config.read(path_scopus + '/config.ini')\n",
    "    #print(config.get(\"Authentication\", \"apikey\"))\n",
    "    k = keys.index(str(config.get(\"Authentication\", \"apikey\")))\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def articlesInfo(articles_eids,keys):\n",
    "    \n",
    "    # Qual a chave que está sendo utilizada\n",
    "    k = keyNumber()\n",
    "    \n",
    "    info_journals = {}\n",
    "    info_articles = {}\n",
    "    n = len(articles_eids)\n",
    "    \n",
    "    for i in tqdm(range(n)):\n",
    "        eid = articles_eids[i]\n",
    "        \n",
    "        id_article = len(info_articles) + 1\n",
    "        #print('Início da extração das informações do artigo ' + str(id_article))\n",
    "\n",
    "        resultado = False \n",
    "        while resultado == False:\n",
    "            try: \n",
    "                infos = sc.AbstractRetrieval(eid , view='FULL', refresh=True)\n",
    "                resultado = True\n",
    "                delete = True\n",
    "            except sc.exception.Scopus404Error:  #NOT FOUND\n",
    "                resultado = True\n",
    "            except sc.exception.Scopus429Error : #QUOTA EXCEEDED\n",
    "                k = k + 1\n",
    "                if k == 11:\n",
    "                    keys = createKeys(password,email)\n",
    "                    k = 0\n",
    "                    changeKeys(k,keys)\n",
    "                else:\n",
    "                    changeKeys(k,keys)\n",
    "            except sc.exception.Scopus500Error:  #INTERNAL SERVER ERROR\n",
    "                time.sleep(14)\n",
    "\n",
    "        if infos.issn != None:\n",
    "\n",
    "            aux_issn = infos.issn.split(' ')\n",
    "            m=0\n",
    "            n=1\n",
    "            issn = aux_issn[0]\n",
    "\n",
    "            if len(aux_issn) == 1: \n",
    "                n = 0\n",
    "\n",
    "            if info_journals.get(aux_issn[m]) == None and info_journals.get(aux_issn[n]) == None:\n",
    "\n",
    "                id_journal = len(info_journals) + 1\n",
    "                info_journals[issn] = {\"ID_J\": id_journal,\n",
    "                                       \"TITLE_J\": infos.publicationName}\n",
    "\n",
    "            elif info_journals.get(aux_issn[0]) != None:\n",
    "                id_journal = info_journals[issn]['ID_J']\n",
    "\n",
    "            else:\n",
    "                issn = aux_issn[1]\n",
    "                id_journal = info_journals[issn]['ID_J']\n",
    "\n",
    "        else: \n",
    "            issn = infos.publicationName\n",
    "            if info_journals.get(issn) == None:\n",
    "                id_journal = len(info_journals) + 1\n",
    "                info_journals[issn] = {\"ID_J\": id_journal,\n",
    "                                       \"TITLE_J\": infos.publicationName}\n",
    "            else:\n",
    "                id_journal = info_journals[issn]['ID_J']\n",
    "\n",
    "        refs = infos.references\n",
    "        refs_eids = []\n",
    "        if refs != None:\n",
    "            for r in range(len(refs)):\n",
    "                refs_eids.append(refs[r][1])\n",
    "\n",
    "        authors = {}\n",
    "        if infos.authors != None:\n",
    "            for a in range(len(infos.authors)):\n",
    "                authors['author_' + str(a)] ={'auid': infos.authors[a][0],\n",
    "                                              'indexed_name': infos.authors[a][1],\n",
    "                                              'affiliation': infos.authors[a][-1]}\n",
    "\n",
    "        try: \n",
    "            cited = infos.citedby_count\n",
    "        except KeyError:\n",
    "            cited = 'NaN'\n",
    "\n",
    "        info_articles[eid] = {\"ID_A\": id_article,\n",
    "                              \"TITLE_A\": infos.title,\n",
    "                              \"DOI\": infos.doi,\n",
    "                              \"YEAR\": infos.coverDate,\n",
    "                              \"AUTHORS\": authors,\n",
    "                              \"ISSN\": issn,\n",
    "                              \"ID_J\": id_journal,\n",
    "                              \"TITLE_J\": infos.publicationName,\n",
    "                              \"REFS\": refs_eids,\n",
    "                              \"CITED_BY_COUNT\": cited}\n",
    "\n",
    "        gc.collect()\n",
    "        \n",
    "        try:\n",
    "            os.remove(path_scopus + '/abstract_retrieval/FULL/' + eid)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "\n",
    "        with open('pickles/' + category + '_INFOS.pickle', 'wb') as f:\n",
    "                pickle.dump([info_articles,info_journals], f)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "articlesInfo(articlesSource,keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('pickles/' + category + '_INFOS.pickle', 'wb') as f:\n",
    "    pickle.dump([info_articles,info_journals], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Usando a API do Scopus, extrair e armazenar as informações das referências de cada artigo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/' + category + '_INFOS.pickle', 'rb') as f:\n",
    "    [info_articles, info_journals] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de Periódicos: 18\n"
     ]
    }
   ],
   "source": [
    "print('Total de Periódicos: ' + str(len(info_journals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de Artigos publicados na área de Lógica: 18718\n"
     ]
    }
   ],
   "source": [
    "print('Total de Artigos publicados na área de Lógica: ' + str(len(info_articles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID_J': 1, 'TITLE_J': 'Algebra and Logic'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_journals['00025232']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AUTHORS': {'author_0': {'affiliation': ['60069255'],\n",
       "   'auid': '56494981800',\n",
       "   'indexed_name': 'Murzina V.F.'}},\n",
       " 'CITED_BY_COUNT': 0,\n",
       " 'DOI': '10.1007/s10469-008-9032-y',\n",
       " 'ID_A': 1,\n",
       " 'ID_J': 1,\n",
       " 'ISSN': '00025232',\n",
       " 'REFS': ['37249034039',\n",
       "  '27544481093',\n",
       "  '27544473747',\n",
       "  '0040575976',\n",
       "  '84976646107',\n",
       "  '0005645110'],\n",
       " 'TITLE_A': 'Temporal logic of linearly ordered α-spaces',\n",
       " 'TITLE_J': 'Algebra and Logic',\n",
       " 'YEAR': '2008-11-01'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_articles['2-s2.0-58049151597']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['37249034039',\n",
       " '27544481093',\n",
       " '27544473747',\n",
       " '0040575976',\n",
       " '84976646107',\n",
       " '0005645110']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_articles['2-s2.0-58049151597']['REFS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos perceber, a estrtura da codifcação dos artigos da base está diferente das referências citadas pelo mesmo (sequência apenas numérica). A codificação dos artigos da base possuem a mesma sequência numérica, porém com o seguinte prefixo: **2-s2.0-**. Se não deixarmos padronizadas, como tais sequências são as chaves do dicionário com as informações de todos os artigos, se algum artigo da base aparecer nas referências de outro artigo, ele será inserido novamente no dicionário com outra chave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refsInfo(source_eids, info_journals, info_articles):\n",
    "    \n",
    "    # Qual a chave que está sendo utilizada\n",
    "    k = keyNumber()\n",
    "\n",
    "    art = 0\n",
    "    n = len(source_eids)\n",
    "    \n",
    "    for i in tqdm(range(n)):\n",
    "        eid = source_eids[i]\n",
    "        REFS = info_articles[eid]['REFS']\n",
    "        art = art +  1\n",
    "        #print('Início da extração das informações das citações do artigo ' + str(art))\n",
    "        cit = 0\n",
    "        \n",
    "        if len(REFS) != 0:\n",
    "            for ref in REFS:\n",
    "                cit = cit + 1\n",
    "                ref = '2-s2.0-' + ref\n",
    "                if info_articles.get(ref) == None:\n",
    "                    \n",
    "                    id_article = len(info_articles) + 1\n",
    "                    \n",
    "                    resultado = False \n",
    "                    while resultado == False:\n",
    "                        try: \n",
    "                            infos = sc.AbstractRetrieval(ref , view='FULL', refresh=True)\n",
    "                            resultado = True\n",
    "                            delete = True\n",
    "                        except sc.exception.Scopus404Error:  #NOT FOUND\n",
    "                            resultado = True\n",
    "                        except sc.exception.Scopus429Error : #QUOTA EXCEEDED\n",
    "                            k = k + 1\n",
    "                            if k == 11:\n",
    "                                keys = createKeys(password,email)\n",
    "                                k = 0\n",
    "                                changeKeys(k,keys)\n",
    "                            else:\n",
    "                                changeKeys(k,keys)\n",
    "                        except sc.exception.Scopus500Error:  #INTERNAL SERVER ERROR\n",
    "                            time.sleep(14)\n",
    "                    \n",
    "                    if infos.issn != None:\n",
    "                        aux_issn = infos.issn.split(' ')\n",
    "                        m=0\n",
    "                        n=1\n",
    "                        issn = aux_issn[0]\n",
    "\n",
    "                        if len(aux_issn) == 1: \n",
    "                            n = 0\n",
    "                        \n",
    "                        if info_journals.get(aux_issn[m]) == None and info_journals.get(aux_issn[n]) == None:\n",
    "\n",
    "                            id_journal = len(info_journals) + 1\n",
    "                            info_journals[issn] = {\"ID_J\": id_journal,\n",
    "                                                   \"TITLE_J\": infos.publicationName}\n",
    "\n",
    "                        elif info_journals.get(aux_issn[0]) != None:\n",
    "                            id_journal = info_journals[issn]['ID_J']\n",
    "\n",
    "                        else:\n",
    "                            issn = aux_issn[1]\n",
    "                            id_journal = info_journals[issn]['ID_J']\n",
    "\n",
    "                    else: \n",
    "                        issn = infos.publicationName\n",
    "                        if info_journals.get(issn) == None:\n",
    "                            id_journal = len(info_journals) + 1\n",
    "                            info_journals[issn] = {\"ID_J\": id_journal,\n",
    "                                                   \"TITLE_J\": infos.publicationName}\n",
    "                        else:\n",
    "                            id_journal = info_journals[issn]['ID_J']\n",
    "\n",
    "\n",
    "                    refs = infos.references\n",
    "                    refs_eids = []\n",
    "                    if refs != None:\n",
    "                        for r in range(len(refs)):\n",
    "                            refs_eids.append(refs[r][1])\n",
    "\n",
    "                    authors = {}\n",
    "                    if infos.authors != None:\n",
    "                        for a in range(len(infos.authors)):\n",
    "                            authors['author_' + str(a)] ={'auid': infos.authors[a][0],\n",
    "                                                          'indexed_name': infos.authors[a][1],\n",
    "                                                          'affiliation': infos.authors[a][-1]}\n",
    "\n",
    "                    try: \n",
    "                        cited = infos.citedby_count\n",
    "                    except KeyError:\n",
    "                        cited = 'NaN'\n",
    "\n",
    "                    info_articles[ref] = {\"ID_A\": id_article,\n",
    "                                          \"TITLE_A\": infos.title,\n",
    "                                          \"DOI\": infos.doi,\n",
    "                                          \"YEAR\": infos.coverDate,\n",
    "                                          \"AUTHORS\": authors,\n",
    "                                          \"ISSN\": issn,\n",
    "                                          \"ID_J\": id_journal,\n",
    "                                          \"TITLE_J\": infos.publicationName,\n",
    "                                          \"REFS\": refs_eids,\n",
    "                                          \"CITED_BY_COUNT\": cited}\n",
    "\n",
    "                    gc.collect()\n",
    "                    \n",
    "                    try:\n",
    "                        os.remove(path_scopus + '/abstract_retrieval/FULL' + ref)\n",
    "                    except FileNotFoundError:\n",
    "                        continue\n",
    "\n",
    "            with open('pickles/' + category + '_REFS.pickle', 'wb') as f:\n",
    "                pickle.dump([info_articles,info_journals], f)\n",
    "        pass\n",
    "\n",
    "    with open('pickles/' + category + '_REFS.pickle', 'wb') as f:\n",
    "        pickle.dump([info_articles,info_journals], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "refsInfo(source_eids, info_journals, info_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/' + category + '_REFS.pickle', 'rb') as f:\n",
    "    [info_articles, info_journals, ref_error] = pickle.load(f)\n",
    "    #[info_articles, info_journals] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de Artigos: 187938\n",
      "Total de Periódicos: 52267\n"
     ]
    }
   ],
   "source": [
    "print(\"Total de Artigos: \" + str(len(info_articles)))\n",
    "print(\"Total de Periódicos: \" + str(len(info_journals)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
